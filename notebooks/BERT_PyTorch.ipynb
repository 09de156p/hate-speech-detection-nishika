{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOeJQqsXZf3FAez8TuFzocR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1ef35625e9a445b0ad0b758389fdf904":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6f53faf330f4d5f89666a4570b7db78","IPY_MODEL_bfb80d24fc0c4ac0845577d98afb4ae7","IPY_MODEL_389fc30087ed4ffdbf7c93b5ec684b5e"],"layout":"IPY_MODEL_80e64444a5054b378892e722a8dcef6c"}},"d6f53faf330f4d5f89666a4570b7db78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaf8e9276b714d1dbc9dd133335e850d","placeholder":"​","style":"IPY_MODEL_888897b06ef846bca55f83256c8f3605","value":"Downloading: 100%"}},"bfb80d24fc0c4ac0845577d98afb4ae7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8034b588783f446c9e617997110636ad","max":257706,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8ac609f924c4dfc8187bf599ca1cb3d","value":257706}},"389fc30087ed4ffdbf7c93b5ec684b5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c75eac2d05d4694a598463d6f579aea","placeholder":"​","style":"IPY_MODEL_fd9a668737814359a4508c7f6b359448","value":" 258k/258k [00:00&lt;00:00, 1.75MB/s]"}},"80e64444a5054b378892e722a8dcef6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf8e9276b714d1dbc9dd133335e850d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"888897b06ef846bca55f83256c8f3605":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8034b588783f446c9e617997110636ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8ac609f924c4dfc8187bf599ca1cb3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c75eac2d05d4694a598463d6f579aea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd9a668737814359a4508c7f6b359448":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad9d6ee628743fa9075026ad7d320f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05c7c0c70d504a75bfdf4dab883e35c4","IPY_MODEL_0c6419836c454eb68baed7e3e47326f1","IPY_MODEL_44459511738d4a31931fa04f4ab9ad76"],"layout":"IPY_MODEL_eaeb630ea331410da585949d9a59fd43"}},"05c7c0c70d504a75bfdf4dab883e35c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c69545bb7c484f33b6bceba84bc676fa","placeholder":"​","style":"IPY_MODEL_4655d3159d8d41fb8d88bf92772e9a86","value":"Downloading: 100%"}},"0c6419836c454eb68baed7e3e47326f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10b8315bf041486eb67d46ea6215df11","max":110,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6439a22eb084f78a2ba1929d0e95cf0","value":110}},"44459511738d4a31931fa04f4ab9ad76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_733451ed03764507b01ec0483b591fac","placeholder":"​","style":"IPY_MODEL_9171cb2409a24ec9aa7f5447f25a5ba9","value":" 110/110 [00:00&lt;00:00, 4.49kB/s]"}},"eaeb630ea331410da585949d9a59fd43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c69545bb7c484f33b6bceba84bc676fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4655d3159d8d41fb8d88bf92772e9a86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10b8315bf041486eb67d46ea6215df11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6439a22eb084f78a2ba1929d0e95cf0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"733451ed03764507b01ec0483b591fac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9171cb2409a24ec9aa7f5447f25a5ba9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1dc579b9d9a4369ad075ca88b6fa80e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9bad2ad703e34d3a92b3ddfe556bf498","IPY_MODEL_01849cc1b8f34519a942716e2585f411","IPY_MODEL_bc193ec158c348f588494a409bb0d511"],"layout":"IPY_MODEL_815c935b09334097aaac46a7fe7d9b71"}},"9bad2ad703e34d3a92b3ddfe556bf498":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3e1664fc0f3409497397b1bff16fa9d","placeholder":"​","style":"IPY_MODEL_4fa7f1876f4d4620bf0e2b11e2509fcc","value":"Downloading: 100%"}},"01849cc1b8f34519a942716e2585f411":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2da58275f42d45918a8eccd06d9a844c","max":479,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30f2c0249ded4723b4378c9819b840dc","value":479}},"bc193ec158c348f588494a409bb0d511":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bb7197ffe604706a41b594e7d9d4f33","placeholder":"​","style":"IPY_MODEL_1e610704d38e49fcbf8bb12999477ef5","value":" 479/479 [00:00&lt;00:00, 19.8kB/s]"}},"815c935b09334097aaac46a7fe7d9b71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e1664fc0f3409497397b1bff16fa9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fa7f1876f4d4620bf0e2b11e2509fcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2da58275f42d45918a8eccd06d9a844c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30f2c0249ded4723b4378c9819b840dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bb7197ffe604706a41b594e7d9d4f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e610704d38e49fcbf8bb12999477ef5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5dcbf88b30f46b39e5626bcc16c5783":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_187d3c9fabcc406187af2c53417ed863","IPY_MODEL_96dc4cacf3b3439788ce82952c583e1c","IPY_MODEL_8b19eeb76bc6467eb959786be42ae22c"],"layout":"IPY_MODEL_ede12b0fb116483bac74620469268dbe"}},"187d3c9fabcc406187af2c53417ed863":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9599a533e3ec4e3b868eb95f103e94af","placeholder":"​","style":"IPY_MODEL_b7daf53be76344a4894bbcdbd0f3b1ae","value":"Downloading: 100%"}},"96dc4cacf3b3439788ce82952c583e1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3064ded126464152ba0d031395b44055","max":445021143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_214ade1d02c84495981bead040c5f372","value":445021143}},"8b19eeb76bc6467eb959786be42ae22c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39e3a29a33d74602af48cb883257d464","placeholder":"​","style":"IPY_MODEL_cbd3fab06d5b422bbafc00695235ab90","value":" 445M/445M [00:07&lt;00:00, 64.1MB/s]"}},"ede12b0fb116483bac74620469268dbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9599a533e3ec4e3b868eb95f103e94af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7daf53be76344a4894bbcdbd0f3b1ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3064ded126464152ba0d031395b44055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"214ade1d02c84495981bead040c5f372":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39e3a29a33d74602af48cb883257d464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbd3fab06d5b422bbafc00695235ab90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 参考サイト\n","[Qiita記事](https://qiita.com/takubb/items/fd972f0ac3dba909c293)"],"metadata":{"id":"6-4QjArvXaS5"}},{"cell_type":"markdown","source":["## 準備"],"metadata":{"id":"BA703eqiYFQJ"}},{"cell_type":"code","source":["# ドライブをマウント\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJuUXAWLjPHv","executionInfo":{"status":"ok","timestamp":1665825886501,"user_tz":-540,"elapsed":19024,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"1e9f645a-223d-4960-a5cc-d215030a7b23"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poJ0Tw9vb05Z","executionInfo":{"status":"ok","timestamp":1665825895426,"user_tz":-540,"elapsed":8931,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"d133e7fc-faa2-4014-b343-04461817c620"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 50.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 88.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["!apt install aptitude swig"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Yagq1iScFYw","executionInfo":{"status":"ok","timestamp":1665825907962,"user_tz":-540,"elapsed":12543,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"cb6d5fff-ff45-4131-b942-305cc28f7357"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n","  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n","  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n","  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n","  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n","  swig3.0\n","Suggested packages:\n","  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n","  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n","  libwww-perl xapian-tools swig-doc swig-examples swig3.0-examples swig3.0-doc\n","The following NEW packages will be installed:\n","  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n","  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n","  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n","  libhttp-message-perl libio-html-perl libio-string-perl\n","  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n","  libsub-name-perl libtimedate-perl liburi-perl libxapian30 swig swig3.0\n","0 upgraded, 23 newly installed, 0 to remove and 12 not upgraded.\n","Need to get 4,978 kB of archives.\n","After this operation, 21.4 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n","Fetched 4,978 kB in 1s (8,438 kB/s)\n","Selecting previously unselected package aptitude-common.\n","(Reading database ... 123934 files and directories currently installed.)\n","Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n","Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n","Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n","Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Selecting previously unselected package libcwidget3v5:amd64.\n","Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n","Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n","Selecting previously unselected package libxapian30:amd64.\n","Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n","Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Selecting previously unselected package aptitude.\n","Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n","Unpacking aptitude (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libhtml-tagset-perl.\n","Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n","Unpacking libhtml-tagset-perl (3.20-3) ...\n","Selecting previously unselected package liburi-perl.\n","Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n","Unpacking liburi-perl (1.73-1) ...\n","Selecting previously unselected package libhtml-parser-perl.\n","Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n","Unpacking libhtml-parser-perl (3.72-3build1) ...\n","Selecting previously unselected package libcgi-pm-perl.\n","Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n","Unpacking libcgi-pm-perl (4.38-1) ...\n","Selecting previously unselected package libfcgi-perl.\n","Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n","Unpacking libfcgi-perl (0.78-2build1) ...\n","Selecting previously unselected package libcgi-fast-perl.\n","Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n","Unpacking libcgi-fast-perl (1:2.13-1) ...\n","Selecting previously unselected package libsub-name-perl.\n","Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n","Unpacking libsub-name-perl (0.21-1build1) ...\n","Selecting previously unselected package libclass-accessor-perl.\n","Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n","Unpacking libclass-accessor-perl (0.51-1) ...\n","Selecting previously unselected package libencode-locale-perl.\n","Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n","Unpacking libencode-locale-perl (1.05-1) ...\n","Selecting previously unselected package libtimedate-perl.\n","Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n","Unpacking libtimedate-perl (2.3000-2) ...\n","Selecting previously unselected package libhttp-date-perl.\n","Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n","Unpacking libhttp-date-perl (6.02-1) ...\n","Selecting previously unselected package libio-html-perl.\n","Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n","Unpacking libio-html-perl (1.001-1) ...\n","Selecting previously unselected package liblwp-mediatypes-perl.\n","Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n","Unpacking liblwp-mediatypes-perl (6.02-1) ...\n","Selecting previously unselected package libhttp-message-perl.\n","Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n","Unpacking libhttp-message-perl (6.14-1) ...\n","Selecting previously unselected package libio-string-perl.\n","Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n","Unpacking libio-string-perl (1.08-3) ...\n","Selecting previously unselected package libparse-debianchangelog-perl.\n","Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n","Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n","Selecting previously unselected package swig3.0.\n","Preparing to unpack .../21-swig3.0_3.0.12-1_amd64.deb ...\n","Unpacking swig3.0 (3.0.12-1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../22-swig_3.0.12-1_amd64.deb ...\n","Unpacking swig (3.0.12-1) ...\n","Setting up libhtml-tagset-perl (3.20-3) ...\n","Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Setting up swig3.0 (3.0.12-1) ...\n","Setting up libencode-locale-perl (1.05-1) ...\n","Setting up libtimedate-perl (2.3000-2) ...\n","Setting up libio-html-perl (1.001-1) ...\n","Setting up aptitude-common (0.8.10-6ubuntu1) ...\n","Setting up liblwp-mediatypes-perl (6.02-1) ...\n","Setting up liburi-perl (1.73-1) ...\n","Setting up libhtml-parser-perl (3.72-3build1) ...\n","Setting up libcgi-pm-perl (4.38-1) ...\n","Setting up libio-string-perl (1.08-3) ...\n","Setting up libsub-name-perl (0.21-1build1) ...\n","Setting up libfcgi-perl (0.78-2build1) ...\n","Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Setting up libclass-accessor-perl (0.51-1) ...\n","Setting up swig (3.0.12-1) ...\n","Setting up libhttp-date-perl (6.02-1) ...\n","Setting up libcgi-fast-perl (1:2.13-1) ...\n","Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n","Setting up libhttp-message-perl (6.14-1) ...\n","Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n","Setting up aptitude (0.8.10-6ubuntu1) ...\n","update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n"]}]},{"cell_type":"code","source":["!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipLnh_gUcLJc","executionInfo":{"status":"ok","timestamp":1665825927247,"user_tz":-540,"elapsed":19302,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"1525cca7-3bb9-4b11-83f8-076048dc5f8e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["git is already installed at the requested version (1:2.17.1-1ubuntu0.12)\n","make is already installed at the requested version (4.1-9.1ubuntu1)\n","curl is already installed at the requested version (7.58.0-2ubuntu3.20)\n","xz-utils is already installed at the requested version (5.2.2-1.3ubuntu0.1)\n","git is already installed at the requested version (1:2.17.1-1ubuntu0.12)\n","make is already installed at the requested version (4.1-9.1ubuntu1)\n","curl is already installed at the requested version (7.58.0-2ubuntu3.20)\n","xz-utils is already installed at the requested version (5.2.2-1.3ubuntu0.1)\n","The following NEW packages will be installed:\n","  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n","The following packages will be REMOVED:\n","  libnvidia-common-460{u} \n","0 packages upgraded, 11 newly installed, 1 to remove and 12 not upgraded.\n","Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n","Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n","Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n","Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n","Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n","Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n","Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n","Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n","Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n","Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n","Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n","Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n","Fetched 29.3 MB in 1s (36.3 MB/s)\n","(Reading database ... 125184 files and directories currently installed.)\n","Removing libnvidia-common-460 (460.106.00-0ubuntu1) ...\n","Selecting previously unselected package libmagic-mgc.\n","(Reading database ... 125179 files and directories currently installed.)\n","Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package libmagic1:amd64.\n","Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package file.\n","Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking file (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package libmecab2:amd64.\n","Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n","Unpacking libmecab2:amd64 (0.996-5) ...\n","Selecting previously unselected package libmecab-dev.\n","Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n","Unpacking libmecab-dev (0.996-5) ...\n","Selecting previously unselected package mecab-utils.\n","Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n","Unpacking mecab-utils (0.996-5) ...\n","Selecting previously unselected package mecab-jumandic-utf8.\n","Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Selecting previously unselected package mecab-jumandic.\n","Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic (7.0-20130310-4) ...\n","Selecting previously unselected package mecab-ipadic.\n","Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n","Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n","Selecting previously unselected package mecab.\n","Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n","Unpacking mecab (0.996-5) ...\n","Selecting previously unselected package mecab-ipadic-utf8.\n","Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n","Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n","Setting up libmecab2:amd64 (0.996-5) ...\n","Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Setting up mecab-utils (0.996-5) ...\n","Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up libmecab-dev (0.996-5) ...\n","Setting up file (1:5.32-2ubuntu0.4) ...\n","Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Compiling Juman dictionary for Mecab.\n","reading /usr/share/mecab/dic/juman/unk.def ... 37\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n","reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n","reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n","reading /usr/share/mecab/dic/juman/Special.csv ... 158\n","reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n","reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n","reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n","reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n","reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n","reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n","reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n","reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n","reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n","reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n","reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n","reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up mecab (0.996-5) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-jumandic (7.0-20130310-4) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n","                            \n"]}]},{"cell_type":"code","source":["!pip install mecab-python3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tV4N4ktecbrO","executionInfo":{"status":"ok","timestamp":1665825931049,"user_tz":-540,"elapsed":3807,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"45709bed-545a-4b3a-c147-2bdee736884c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mecab-python3\n","  Downloading mecab_python3-1.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (574 kB)\n","\u001b[K     |████████████████████████████████| 574 kB 4.8 MB/s \n","\u001b[?25hInstalling collected packages: mecab-python3\n","Successfully installed mecab-python3-1.0.5\n"]}]},{"cell_type":"markdown","source":["## ライブラリ、データセットの読み込み"],"metadata":{"id":"pVPleW7zYQG8"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","\n","# GPUが使えれば利用する設定\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"使用デバイス：\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6ftUJ76ccbk","executionInfo":{"status":"ok","timestamp":1665825933191,"user_tz":-540,"elapsed":2155,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"0ca63d42-c65b-465b-860f-20f6794103e7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["使用デバイス： cuda:0\n"]}]},{"cell_type":"code","source":["dir = \"/content/drive/My Drive/hate-speech-detection-nishika/data/raw/\"\n","\n","train_raw = pd.read_csv(f\"{dir}train.csv\")\n","train = train_raw\n","train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"xPS1ysOaiG0g","executionInfo":{"status":"ok","timestamp":1665827155009,"user_tz":-540,"elapsed":358,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"3e5c5d2a-5e41-4ea0-8642-0124a288ec0a"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id       source                                               text  \\\n","0  80074aa43     news4vip                  まともに相手されてない人との関係なんて\\nそんな大事にするものか？   \n","1  6378fea6b  livejupiter             最近はアヘアヘQSマンやない？ ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!   \n","2  c535f5613  livejupiter    日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな   \n","3  e76638295  livejupiter   よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで   \n","4  51e4036bf     newsplus  押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...   \n","\n","   label  \n","0      0  \n","1      0  \n","2      1  \n","3      0  \n","4      0  "],"text/html":["\n","  <div id=\"df-73999f04-63ae-4689-ad62-6530e3216243\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>80074aa43</td>\n","      <td>news4vip</td>\n","      <td>まともに相手されてない人との関係なんて\\nそんな大事にするものか？</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6378fea6b</td>\n","      <td>livejupiter</td>\n","      <td>最近はアヘアヘQSマンやない？ ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>c535f5613</td>\n","      <td>livejupiter</td>\n","      <td>日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>e76638295</td>\n","      <td>livejupiter</td>\n","      <td>よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>51e4036bf</td>\n","      <td>newsplus</td>\n","      <td>押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73999f04-63ae-4689-ad62-6530e3216243')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-73999f04-63ae-4689-ad62-6530e3216243 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-73999f04-63ae-4689-ad62-6530e3216243');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# データの抽出（numpy.ndarray）\n","sentences = train.text.values\n","labels = train.label.values"],"metadata":{"id":"KT4XAAP4isic","executionInfo":{"status":"ok","timestamp":1665827155267,"user_tz":-540,"elapsed":2,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["## データの前処理"],"metadata":{"id":"k-26hKWPYlAl"}},{"cell_type":"code","source":["# 1. BERT Tokenizerを用いて単語分割・IDへ変換\n","## Tokenizerの準備\n","from transformers import BertJapaneseTokenizer"],"metadata":{"id":"XGEXznSKkGrM","executionInfo":{"status":"ok","timestamp":1665825933923,"user_tz":-540,"elapsed":293,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!pip install fugashi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxWcgL6qlNRj","executionInfo":{"status":"ok","timestamp":1665825937872,"user_tz":-540,"elapsed":3953,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"6f868151-ea69-4d65-ee14-70145337552f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fugashi\n","  Downloading fugashi-1.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (583 kB)\n","\u001b[K     |████████████████████████████████| 583 kB 4.7 MB/s \n","\u001b[?25hInstalling collected packages: fugashi\n","Successfully installed fugashi-1.2.0\n"]}]},{"cell_type":"code","source":["!pip install ipadic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RSOhXGBlhK3","executionInfo":{"status":"ok","timestamp":1665825946732,"user_tz":-540,"elapsed":8866,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"d2e74811-66ef-4870-a2c3-0fd380a564c8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ipadic\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[K     |████████████████████████████████| 13.4 MB 4.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: ipadic\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=237f9edc13165da9470114aa83f248bb2eca665e920e9bc329d3dd3de9ef10d8\n","  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n","Successfully built ipadic\n","Installing collected packages: ipadic\n","Successfully installed ipadic-1.0.0\n"]}]},{"cell_type":"code","source":["# Load pre-trained tokenizer\n","tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["1ef35625e9a445b0ad0b758389fdf904","d6f53faf330f4d5f89666a4570b7db78","bfb80d24fc0c4ac0845577d98afb4ae7","389fc30087ed4ffdbf7c93b5ec684b5e","80e64444a5054b378892e722a8dcef6c","eaf8e9276b714d1dbc9dd133335e850d","888897b06ef846bca55f83256c8f3605","8034b588783f446c9e617997110636ad","e8ac609f924c4dfc8187bf599ca1cb3d","7c75eac2d05d4694a598463d6f579aea","fd9a668737814359a4508c7f6b359448","dad9d6ee628743fa9075026ad7d320f2","05c7c0c70d504a75bfdf4dab883e35c4","0c6419836c454eb68baed7e3e47326f1","44459511738d4a31931fa04f4ab9ad76","eaeb630ea331410da585949d9a59fd43","c69545bb7c484f33b6bceba84bc676fa","4655d3159d8d41fb8d88bf92772e9a86","10b8315bf041486eb67d46ea6215df11","c6439a22eb084f78a2ba1929d0e95cf0","733451ed03764507b01ec0483b591fac","9171cb2409a24ec9aa7f5447f25a5ba9","e1dc579b9d9a4369ad075ca88b6fa80e","9bad2ad703e34d3a92b3ddfe556bf498","01849cc1b8f34519a942716e2585f411","bc193ec158c348f588494a409bb0d511","815c935b09334097aaac46a7fe7d9b71","f3e1664fc0f3409497397b1bff16fa9d","4fa7f1876f4d4620bf0e2b11e2509fcc","2da58275f42d45918a8eccd06d9a844c","30f2c0249ded4723b4378c9819b840dc","1bb7197ffe604706a41b594e7d9d4f33","1e610704d38e49fcbf8bb12999477ef5"]},"id":"L8XVl1dnka1N","executionInfo":{"status":"ok","timestamp":1665825948248,"user_tz":-540,"elapsed":1527,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"dd78eedd-6454-45df-ebb4-fc6e8e1e8a69"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/258k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ef35625e9a445b0ad0b758389fdf904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/110 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dad9d6ee628743fa9075026ad7d320f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/479 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1dc579b9d9a4369ad075ca88b6fa80e"}},"metadata":{}}]},{"cell_type":"code","source":["## テスト実行\n","for i in range(3):\n","  # 元文章\n","  print(' Original: ', sentences[i])\n","  # Tokenizer\n","  print('Tokenized: ', tokenizer.tokenize(sentences[i]))\n","  # Token-id\n","  print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[i])))\n","  print(\"=\" * 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4GkbLFotk_Kt","executionInfo":{"status":"ok","timestamp":1665825948248,"user_tz":-540,"elapsed":6,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"6db87930-184b-4742-a196-a92bd27e5d1c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original:  まともに相手されてない人との関係なんて\n","そんな大事にするものか？\n","Tokenized:  ['まとも', 'に', '相手', 'さ', 'れ', 'て', 'ない', '人', 'と', 'の', '関係', 'なんて', 'そんな', '大事', 'に', 'する', 'もの', 'か', '?']\n","Token IDs:  [23135, 7, 1879, 26, 20, 16, 80, 53, 13, 5, 633, 15060, 4799, 15872, 7, 34, 120, 29, 2935]\n","====================\n"," Original:  最近はアヘアヘQSマンやない？ ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!\n","Tokenized:  ['最近', 'は', 'ア', '##ヘ', '##ア', '##ヘ', 'Q', '##S', 'マン', 'や', 'ない', '?', 'イ', '##イ', '!(', '・', '[UNK]', '・', ')', '##+', '1', '-', '0', '(', '・', 'A', '・', ')', 'イ', '##ク', '##ナイ', '!']\n","Token IDs:  [5233, 9, 43, 28962, 28483, 28962, 2984, 28583, 1490, 49, 80, 2935, 88, 28478, 21567, 35, 1, 35, 24, 29676, 17, 61, 518, 23, 35, 192, 35, 24, 88, 28488, 4114, 679]\n","====================\n"," Original:  日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\n","甘えるな\n","Tokenized:  ['日本人', 'として', '生まれ', 'て', 'も', '無', '##能', 'な', '低', '学歴', 'って', '分かっ', 'たら', '日本人', 'の', '権利', '剥奪', 'し', 'て', '追放', 'す', 'べき', 'やろ', '甘', '##える', 'な']\n","Token IDs:  [2839, 50, 1115, 16, 28, 348, 28742, 18, 837, 26486, 6172, 8056, 3318, 2839, 5, 3410, 13430, 15, 16, 4856, 340, 1761, 22317, 5063, 358, 18]\n","====================\n"]}]},{"cell_type":"code","source":["# 最大単語数の確認\n","max_len = []\n","# 1文づつ処理\n","for sent in sentences:\n","    # Tokenizeで分割\n","    token_words = tokenizer.tokenize(sent)\n","    # 文章数を取得してリストへ格納\n","    max_len.append(len(token_words))\n","# 最大の値を確認\n","print('最大単語数: ', max(max_len))\n","print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnXMbIo-ls0H","executionInfo":{"status":"ok","timestamp":1665825948910,"user_tz":-540,"elapsed":667,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"c2a26ec6-06a3-4a40-cdab-c5d74a6e4bd9"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["最大単語数:  91\n","上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"]}]},{"cell_type":"code","source":["input_ids = []\n","attention_masks = []\n","\n","# 1文づつ処理\n","for sent in sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      \n","                        add_special_tokens = True, # Special Tokenの追加\n","                        max_length = max(max_len), # 文章の長さを固定（Padding/Trancatinating）\n","                        pad_to_max_length = True,# PADDINGで埋める\n","                        return_attention_mask = True, # Attention maskの作成\n","                        return_tensors = 'pt', #  Pytorch tensorsで返す\n","                   )\n","\n","    # 単語IDを取得    \n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    # Attention_maskの取得\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# リストに入ったtensorを縦方向（dim=0）へ結合\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","# tenosor型に変換\n","labels = torch.tensor(labels)\n","\n","# 確認\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print(\"Attention Masks:\", attention_masks[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1u_0gDg2l1it","executionInfo":{"status":"ok","timestamp":1665825951519,"user_tz":-540,"elapsed":2613,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"3a0b19da-7381-44c6-c60a-adfdc4c4234b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:  まともに相手されてない人との関係なんて\n","そんな大事にするものか？\n","Token IDs: tensor([    2, 23135,     7,  1879,    26,    20,    16,    80,    53,    13,\n","            5,   633, 15060,  4799, 15872,     7,    34,   120,    29,  2935,\n","            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0])\n","Attention Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# データセットクラスの作成\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# 90%地点のIDを取得\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# データセットを分割\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('訓練データ数：{}'.format(train_size))\n","print('検証データ数: {} '.format(val_size))\n","\n","# データローダーの作成\n","batch_size = 32\n","\n","# 訓練データローダー\n","train_dataloader = DataLoader(\n","            train_dataset,  \n","            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n","            batch_size = batch_size\n","        )\n","\n","# 検証データローダー\n","validation_dataloader = DataLoader(\n","            val_dataset, \n","            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n","            batch_size = batch_size\n","        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLZv_-63mOJw","executionInfo":{"status":"ok","timestamp":1665825951520,"user_tz":-540,"elapsed":6,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"67350a4f-0cc7-4f35-d6d5-fa169010f216"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["訓練データ数：4730\n","検証データ数: 526 \n"]}]},{"cell_type":"markdown","source":["## 学習済みデータのロード"],"metadata":{"id":"oHv4nxHeYuyu"}},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# BertForSequenceClassification 学習済みモデルのロード\n","model = BertForSequenceClassification.from_pretrained(\n","    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n","    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n","     output_attentions = False, # アテンションベクトルを出力するか\n","     output_hidden_states = False, # 隠れ層を出力するか\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159,"referenced_widgets":["b5dcbf88b30f46b39e5626bcc16c5783","187d3c9fabcc406187af2c53417ed863","96dc4cacf3b3439788ce82952c583e1c","8b19eeb76bc6467eb959786be42ae22c","ede12b0fb116483bac74620469268dbe","9599a533e3ec4e3b868eb95f103e94af","b7daf53be76344a4894bbcdbd0f3b1ae","3064ded126464152ba0d031395b44055","214ade1d02c84495981bead040c5f372","39e3a29a33d74602af48cb883257d464","cbd3fab06d5b422bbafc00695235ab90"]},"id":"1-NUPm9fmhNw","executionInfo":{"status":"ok","timestamp":1665825963382,"user_tz":-540,"elapsed":11865,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"e5076525-c61f-422a-f1bb-dda205f49d81"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5dcbf88b30f46b39e5626bcc16c5783"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# モデルをGPUへ転送\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R56s1Kf1msm8","executionInfo":{"status":"ok","timestamp":1665825969631,"user_tz":-540,"elapsed":6261,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"9ea0035e-69fa-4f8e-8564-23c33802090d"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## モデルの訓練"],"metadata":{"id":"nTQfLxwiY2Ok"}},{"cell_type":"code","source":["# 最適化手法の設定\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","\n","# 訓練パートの定義\n","def train(model):\n","    model.train() # 訓練モードで実行\n","    train_loss = 0\n","    for batch in train_dataloader: # train_dataloaderはword_id, mask, labelを出力する点に注意\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        optimizer.zero_grad()\n","        loss = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask, \n","                            labels=b_labels).loss # 戻り値とここを修正\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        train_loss += loss.item()\n","    return train_loss\n","\n","# テストパートの定義\n","def validation(model):\n","    model.eval() # 訓練モードをオフ\n","    val_loss = 0\n","    with torch.no_grad(): # 勾配を計算しない\n","        for batch in validation_dataloader:\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)\n","            with torch.no_grad():        \n","                loss = model(b_input_ids, \n","                                    token_type_ids=None, \n","                                    attention_mask=b_input_mask,\n","                                    labels=b_labels).loss # 戻り値とここを修正\n","            val_loss += loss.item()\n","    return val_loss"],"metadata":{"id":"zxhh0Yym0mdR","executionInfo":{"status":"ok","timestamp":1665825969632,"user_tz":-540,"elapsed":14,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# 学習の実行\n","max_epoch = 4\n","train_loss_ = []\n","test_loss_ = []\n","\n","for epoch in range(max_epoch):\n","    train_ = train(model)\n","    test_ = train(model)\n","    train_loss_.append(train_)\n","    test_loss_.append(test_)"],"metadata":{"id":"MMuRBETZsvV2","executionInfo":{"status":"ok","timestamp":1665826120156,"user_tz":-540,"elapsed":150537,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## 検証"],"metadata":{"id":"pF4DM5CsY_ap"}},{"cell_type":"code","source":["# 検証方法の確認（1バッチ分で計算ロジックに確認）\n","\n","model.eval()# 訓練モードをオフ\n","for batch in validation_dataloader:\n","    b_input_ids = batch[0].to(device)\n","    b_input_mask = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","    with torch.no_grad():   \n","        # 学習済みモデルによる予測結果をpredsで取得     \n","        preds = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)"],"metadata":{"id":"F2pEedTpsvTY","executionInfo":{"status":"ok","timestamp":1665826120717,"user_tz":-540,"elapsed":573,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["## 予測結果の確認\n","print(f'出力:{preds}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XnDysWSOsvQo","executionInfo":{"status":"ok","timestamp":1665826120718,"user_tz":-540,"elapsed":10,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"16017745-0273-4dc9-80df-265296bb7960"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["出力:SequenceClassifierOutput(loss=None, logits=tensor([[ 3.9457, -4.0637],\n","        [ 5.2320, -5.3368],\n","        [-2.3556,  1.7274],\n","        [ 5.0173, -5.1747],\n","        [ 5.1083, -5.2576],\n","        [ 5.2648, -5.3423],\n","        [-3.8346,  3.7131],\n","        [ 5.3039, -5.3349],\n","        [ 5.3157, -5.4285],\n","        [ 5.2442, -5.2867],\n","        [ 5.2870, -5.3516],\n","        [ 5.0087, -5.2146],\n","        [ 4.9721, -5.2520],\n","        [ 5.2059, -5.3107]], device='cuda:0'), hidden_states=None, attentions=None)\n"]}]},{"cell_type":"code","source":["# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n","logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n","## np.argmaxで大き方の値を取得\n","pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n","label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n","\n","accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n","\n","accuracy_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"QckJUe06svNa","executionInfo":{"status":"ok","timestamp":1665826120718,"user_tz":-540,"elapsed":8,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"8157134f-f63e-447d-ff19-246b04d18a89"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    logit_0   logit_1  pred_label  true_label\n","0  3.945750 -4.063663           0           0\n","1  5.231976 -5.336770           0           0\n","2 -2.355605  1.727362           1           0\n","3  5.017338 -5.174676           0           0\n","4  5.108286 -5.257620           0           0"],"text/html":["\n","  <div id=\"df-c72327af-bd21-40a3-b05d-4f713c324308\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>logit_0</th>\n","      <th>logit_1</th>\n","      <th>pred_label</th>\n","      <th>true_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.945750</td>\n","      <td>-4.063663</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.231976</td>\n","      <td>-5.336770</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.355605</td>\n","      <td>1.727362</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.017338</td>\n","      <td>-5.174676</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.108286</td>\n","      <td>-5.257620</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c72327af-bd21-40a3-b05d-4f713c324308')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c72327af-bd21-40a3-b05d-4f713c324308 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c72327af-bd21-40a3-b05d-4f713c324308');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["accuracy_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9ijU8QjMF4H","executionInfo":{"status":"ok","timestamp":1665826120718,"user_tz":-540,"elapsed":7,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"71d25c86-c314-4eec-cffe-26f34041c420"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14, 4)"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## 予測"],"metadata":{"id":"tPytvaO49jhp"}},{"cell_type":"code","source":["test_raw = pd.read_csv(f\"{dir}test.csv\")\n","test = test_raw\n","test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"NHBs5Pwt9Zyy","executionInfo":{"status":"ok","timestamp":1665826121001,"user_tz":-540,"elapsed":288,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"79afd9b2-0680-4024-d722-ceea0be5c42d"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id       source                                               text\n","0  001026808     news4vip  上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...\n","1  00465ac96  livejupiter  たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...\n","2  004674725  livejupiter  そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...\n","3  00474460f     news4vip  法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...\n","4  004a7525c     newsplus  別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事..."],"text/html":["\n","  <div id=\"df-a4fc5568-8bdd-4389-98f5-2f8db36d80ed\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>source</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>001026808</td>\n","      <td>news4vip</td>\n","      <td>上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00465ac96</td>\n","      <td>livejupiter</td>\n","      <td>たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004674725</td>\n","      <td>livejupiter</td>\n","      <td>そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00474460f</td>\n","      <td>news4vip</td>\n","      <td>法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>004a7525c</td>\n","      <td>newsplus</td>\n","      <td>別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4fc5568-8bdd-4389-98f5-2f8db36d80ed')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a4fc5568-8bdd-4389-98f5-2f8db36d80ed button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a4fc5568-8bdd-4389-98f5-2f8db36d80ed');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# データの抽出\n","sentences_test = test.text.values\n","\n","# 最大単語数の確認\n","max_len = []\n","# 1文づつ処理\n","for sent in sentences_test:\n","    # Tokenizeで分割\n","    token_words = tokenizer.tokenize(sent)\n","    # 文章数を取得してリストへ格納\n","    max_len.append(len(token_words))\n","# 最大の値を確認\n","print('最大単語数: ', max(max_len))\n","print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')\n","\n","input_ids_test = []\n","attention_masks_test = []\n","\n","# 1文づつ処理\n","for sent in sentences_test:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      \n","                        add_special_tokens = True, # Special Tokenの追加\n","                        max_length = max(max_len),           # 文章の長さを固定（Padding/Trancatinating）\n","                        pad_to_max_length = True,# PADDINGで埋める\n","                        return_attention_mask = True,   # Attention maskの作成\n","                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n","                   )\n","\n","    # 単語IDを取得    \n","    input_ids_test.append(encoded_dict['input_ids'])\n","\n","    # Attention　maskの取得\n","    attention_masks_test.append(encoded_dict['attention_mask'])\n","\n","print(\"input_ids_test:\", len(input_ids_test))\n","print(\"attention_masks_test:\", len(attention_masks_test))\n","\n","# リストに入ったtensorを縦方向（dim=0）へ結合\n","input_ids_test = torch.cat(input_ids_test, dim=0)\n","attention_masks_test = torch.cat(attention_masks_test, dim=0)\n","\n","# 確認\n","print('Original:', sentences_test[0])\n","print('Token IDs:', input_ids_test[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2q8LmpX-Y86","executionInfo":{"status":"ok","timestamp":1665826122924,"user_tz":-540,"elapsed":1926,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"bf84c0bc-b62c-4319-b487-b5936ce3af0b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["最大単語数:  97\n","上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["input_ids_test: 3223\n","attention_masks_test: 3223\n","Original: 上でも言ったけどオタクレベルの知識求めてる訳じゃない\n","ただ囲碁やります！って人が誰1人プロ棋士わかりません、布石も知りませんなら申し訳ないけどお祈りかな\n","Token IDs: tensor([    2,   109,   962,  3083,    10, 11218, 25678,  2900,     5,  4125,\n","         2023,  7134,  3218,  4847,    80,   909, 11155,  4710,  2610,   679,\n","         6172,    53,    14,  3654,    17,    53,   285, 10400, 14428,  6769,\n","         1058,     6,  3432, 28922,    28,  4534,  6769,  1058,   737,  4482,\n","        29522,    80, 11218,    73, 30284, 28477,    29,    18,     3,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0])\n"]}]},{"cell_type":"code","source":["# データセットクラスの作成\n","test_dataset = TensorDataset(input_ids_test, attention_masks_test)\n","\n","# データローダー\n","test_dataloader = DataLoader(\n","            test_dataset, \n","            sampler = SequentialSampler(test_dataset), # 順番にデータを取得してバッチ化\n","            batch_size = batch_size\n","        )"],"metadata":{"id":"UjR4C_cBC-wN","executionInfo":{"status":"ok","timestamp":1665826122924,"user_tz":-540,"elapsed":2,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["list_wakaran = []\n","\n","# testデータを予測\n","model.eval()# 訓練モードをオフ\n","for batch in test_dataloader:\n","  \n","    b_input_ids = batch[0].to(device)\n","    b_input_mask = batch[1].to(device)\n","    with torch.no_grad():   \n","        # 学習済みモデルによる予測結果をpredsで取得     \n","        preds = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","print(preds)\n","# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n","logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n","## np.argmaxで大き方の値を取得\n","pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n","\n","sub_df = pd.concat([logits_df, pred_df], axis=1)\n","\n","sub_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622},"id":"sW51wKiZsvB9","executionInfo":{"status":"ok","timestamp":1665826128772,"user_tz":-540,"elapsed":5850,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"18d519a1-5cde-4199-9b4e-c1c33c5af6af"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["SequenceClassifierOutput(loss=None, logits=tensor([[ 5.3005, -5.4139],\n","        [ 5.1105, -5.2090],\n","        [ 5.2337, -5.3851],\n","        [ 4.9665, -4.9264],\n","        [ 5.3168, -5.4060],\n","        [ 5.3059, -5.3915],\n","        [ 5.2612, -5.3814],\n","        [ 5.2747, -5.3282],\n","        [ 5.2483, -5.3606],\n","        [ 4.9794, -5.0306],\n","        [ 1.8129, -2.0269],\n","        [ 5.3151, -5.4456],\n","        [ 5.2979, -5.3979],\n","        [ 4.0946, -4.3071],\n","        [ 5.2406, -5.3320],\n","        [ 5.1521, -5.2814],\n","        [ 5.2646, -5.4050],\n","        [ 4.6325, -4.7243],\n","        [ 5.2525, -5.3948],\n","        [ 5.1508, -5.3006],\n","        [ 5.2242, -5.3682],\n","        [ 5.1497, -5.3223],\n","        [ 5.2831, -5.4132]], device='cuda:0'), hidden_states=None, attentions=None)\n"]},{"output_type":"execute_result","data":{"text/plain":["    logit_0   logit_1  pred_label\n","0  5.300513 -5.413949           0\n","1  5.110548 -5.208965           0\n","2  5.233718 -5.385134           0\n","3  4.966549 -4.926397           0\n","4  5.316772 -5.405961           0"],"text/html":["\n","  <div id=\"df-75602abd-f1fe-4032-843f-97519e06eae8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>logit_0</th>\n","      <th>logit_1</th>\n","      <th>pred_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.300513</td>\n","      <td>-5.413949</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.110548</td>\n","      <td>-5.208965</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.233718</td>\n","      <td>-5.385134</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.966549</td>\n","      <td>-4.926397</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.316772</td>\n","      <td>-5.405961</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75602abd-f1fe-4032-843f-97519e06eae8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-75602abd-f1fe-4032-843f-97519e06eae8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-75602abd-f1fe-4032-843f-97519e06eae8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["sub_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_wmlzd-A-4O","executionInfo":{"status":"ok","timestamp":1665826128773,"user_tz":-540,"elapsed":25,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}},"outputId":"a8751aef-a189-4f78-8787-387107a0e833"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(23, 3)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":[],"metadata":{"id":"IZRmVJgKRjyl","executionInfo":{"status":"ok","timestamp":1665826128773,"user_tz":-540,"elapsed":21,"user":{"displayName":"kj nkgw","userId":"16512103549059864503"}}},"execution_count":29,"outputs":[]}]}